# this is ../c/maize/crops/notes/procedure.org


how to generate pedigrees, plant tags, field book, and harvest plan
revised <2014-06-02 Mon> :toni:
again revised <2015-09-25 Fri> :toni:
and again <2019-05-21 Tue> :toni:
and again <2019-07-29 Mon> :toni:
and again <2020-05-14 Thu> :toni:
and again <2020-07-17 Fri> :toni:
and again <2020-07-26 Sun> :toni:
and again <2020-09-01 Tue> :toni:
and again <2022-02-15 Tue> :toni:
and again <2022-05-22 Sun> :toni:
and again <2023-05-17 Wed> :toni:


* DONE basic computations

** computing inverted indices
<<indices>>

#+begin_src prolog
$ pwd
/Users/toni/me/c/maize/demeter/code

$ swipl

 ?- [load_demeter].
?- make_indices,halt.
#+end_src
   

** making a new save state
<<save_state>>   

#+begin_src prolog
$ pwd
/Users/toni/me/c/maize/demeter/code

$ swipl
?- ['../data/load_data',set_demeter_directory],qsave_program('../data/saved_data'),halt.

#+end_src


** running code in general
<<genl_code>>


#+begin_src prolog
$ pwd
/Users/toni/me/c/maize/demeter/code

$ ../data/saved_data

?- [load_code].
#+end_src




* TODO fix analyze_crop.pl so that it doesn't exclude rows skipped and then planted! <2023-10-18 Wed>


* DONE Needed software and modules <2020-09-01 Tue>
<<swinst>>


** System Configuration

*** Getting the PATHs correct for Emacs

Emacs gets its shell environment variables a bit differently, and pulls
them from different places when launching emacs from the command line and
the GUI.


So set the environment variables in all the user shell configuration files.
I still use bash (too lazy to migrate syntax on all my scripts!), so for me
that's BOTH [[file:~/.bashrc][.bashrc]] and [[file:~/.bash_profile][.bash_profile]]:
#
#+BEGIN_SRC setting PATH environment variables
#
# Make sure /usr/local/bin is in the path, as most third-party code is linked there
#
export PATH="/usr/local/bin:/opt/X11/bin:/Library/Apple/usr/bin:/Library/Frameworks/Python.framework/Versions/3.8/bin:$PATH"
export PYTHONPATH="/usr/local/bin:/Library/Frameworks/Python.framework/Versions/3.8/bin:$PYTHONPATH"
#+END_SRC
#
(I've included the PYTHONPATH variable for snake charmers.)



Emacs then needs to know where to get these variables.  In your [[file:~/.emacs][.emacs]] file
(or wherever you like to configure emacs):
#
#+BEGIN_SRC elisp

; make sure other packages are available
;
; this is for an installation of Emacs on a Mac:  modify to point to the
; installation directory for your machine

(add-to-list 'load-path "/Applications/Emacs.app/Contents/Resources/site-lisp/")
(add-to-list 'load-path "~/.emacs.d/elpa/")
;; getting and maintaining packages:  this is the easy way!  M-x package-list to
;; get started
;;
;; from http://stackoverflow.com/questions/14836958/updating-packages-in-emacs
;;
;; Kazic, 21.4.2014
;;
(package-initialize)
(add-to-list 'package-archives
             '("melpa" . "http://melpa.milkbox.net/packages/"))

;; install exec-path-from-shell using melpa and M-x list packages

(exec-path-from-shell-copy-env "PATH")
(exec-path-from-shell-copy-env "PYTHONPATH")

#+END_SRC


Restart emacs and check:
#
#+BEGIN_SRC 
$ echo $PATH
/usr/local/bin:/opt/X11/bin:/Library/Apple/usr/bin:/Library/Frameworks/Python.framework/Versions/3.8/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/Emacs.app/Contents/MacOS/bin-x86_64-10_14:/Applications/Emacs.app/Contents/MacOS/libexec-x86_64-10_14
bash-3.2$ echo $PYTHONPATH
/usr/local/bin:/Library/Frameworks/Python.framework/Versions/3.8/bin:
#+END_SRC



*** Liberating Catalina from its Safety Features <2020-09-01 Tue>

[[https://emacs.stackexchange.com/questions/53026/how-to-restore-file-system-access-in-macos-catalina][Clearest instructions]]: basically, System Preferences > Security and Privacy
> {Accessibility,Full Disk Access, Files and Folders, Developer Tools} need
to see Emacs, ruby, etc.

[[https://spin.atomicobject.com/2019/12/12/fixing-emacs-macos-catalina/][This lovely post by Chris Farber]] explains Apple's rationale for restricting
file access, essentially to protect the user's privacy.


** Perl modules

Install Perl >= 5.26 using [[https://perlbrew.pl/][Perlbrew]].


#+begin_src perl
cpan cpan
cpan File::Basename
cpan Cwd
cpan Date::Calc
cpan Data::Dumper
cpan List::Util
cpan List::MoreUtils
cpan Time::Local
cpan File::Path
cpan File::Find
cpan Lingua::EN::Words2Nums
#+end_src


** Other packages

*** [[https://brew.sh/][Homebrew]] for the Mac

These days, I check first for a Homebrew version of a package before I
compile it from source.

For Linuces, there are multiple package managers, and your version probably
already has it installed and uses it.

I have no idea for Windows.


*** [[https://directory.fsf.org/wiki/Barcode#tab=Overview][GNU barcode]]

**** Macs

The easiest way is install it is to use Homebrew:

[[https://formulae.brew.sh/formula/gnu-barcode][homebrew formula]] page, but not the incantation


[[http://macappstore.org/gnu-barcode/][a glossier version]], with incantations

#+BEGIN_SRC homebrew and GNU barcode installation

# not as root!!!! (it will warn you)

sh-3.2# ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" < /dev/null 2> /dev/null
Don't run this as root!


# as a regular user
#
# first install homebrew, which you

toni$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" < /dev/null 2> /dev/null
==> This script will install:
/usr/local/bin/brew
/usr/local/share/doc/homebrew
/usr/local/share/man/man1/brew.1
....
==> Installation successful!


# now install GNU barcode

toni$ brew install gnu-barcode
Updating Homebrew...
==> Downloading https://homebrew.bintray.com/bottles/gnu-barcode-0.99.catalina.bottle.tar.gz
######################################################################## 100.0%
==> Pouring gnu-barcode-0.99.catalina.bottle.tar.gz
🍺  /usr/local/Cellar/gnu-barcode/0.99: 11 files, 206.2KB


# got it!

bash-3.2$ ls -l /usr/local/bin/barcode 
lrwxr-xr-x  1 toni  admin  38 May 15 08:06 /usr/local/bin/barcode -> ../Cellar/gnu-barcode/0.99/bin/barcode
#+END_SRC


**** Other OSes

On Macs, compilation of the source threw ld errors:

https://stackoverflow.com/questions/24298144/duplicate-symbols-for-architecture-x86-64-under-xcode

#+BEGIN_SRC watch out for ld duplicate symbols in source when compiling!

# let the mac automatically unpack the xz archive

sh-3.2# cd ~toni/Downloads/transient/barcode-0.99/

sh-3.2# ./configure
sh-3.2# make


ld: 12 duplicate symbols for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[2]: *** [barcode] Error 1
make[1]: *** [all-recursive] Error 1
make: *** [all] Error 2


sh-3.2# make -v
GNU Make 3.81
Copyright (C) 2006  Free Software Foundation, Inc.
This is free software; see the source for copying conditions.
There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE.

This program built for i386-apple-darwin11.3.0



sh-3.2# ./make install

#+END_SRC


Turns out [[https://github.com/Homebrew/legacy-homebrew/issues/41115][the problem was found in 2015]], patched, but somehow patched GNU
version throws the same error now in this version of mac osx.


My guess is Linuces won't have this problem, but I have no way to test that.



*** Enscript and Ghostscript

[[https://brewinstall.org/install-enscript-on-mac-with-brew/][Enscript]] and [[https://formulae.brew.sh/formula/ghostscript#default][ps2pdf]] must be installed to get pdf output: the links include
the command to install [[https://brew.sh/][Homebrew]].  Note ps2pdf is part of the [[https://www.ghostscript.com/][Ghostscript
suite]].  Make sure that the PATH environment variable is correctly set.




* DONE write code to reassign sleeves after compression!


See [[file:../../data/data_conversion/scootch_sleeve_bdries.perl][scootch_sleeve_bdries.perl]].



* GNG write pedigree integrity checks --- edit text w/pointers


code done!
  
  One is to compute
    the pedigrees by crop and rowplant, rather than by unifying on the
    entire numerical genotype, and compare the two versions.  The other is
    to check for changes in gene and K number assignments along the
    pedigree. 

Right now the simpler ones are done --- see pedigrees.pl.


* DONE preliminaries
<<prelim>>

1. Be sure that [[file:../../demeter/data/crop.pl][crop.pl]] includes all crops that have yielded
offspring.  Usually the most recent crop will be missing.  It must be
present, or none of its offspring will appear in the pedigrees.



2.  Be sure corn is physically filed in inventory order:
   + mutants first, by rowplant (includes crop improvement, selves, etc.);
   + inbreds next, by family and then rowplant;
   + fun corn last.


3.  *Be sure to physically discard all corn* marked "discarded" or
    "ambiguous" in [[file:../../demeter/data/harvest.pl][harvest.pl]]! 


4. Ensure [[file:../../demeter/data/inventory.pl][inventory.pl]] is current, running [[file:../../data/data_conversion/update_inventory.perl][update_inventory.perl]] with the
   last crop if this has been forgotten.  If corn has been compressed,
   reassign sleeves, commenting out the old facts for each sleeve,
   collecting new sleeve boundary data, and scootching sleeve boundaries
   ([[file:../../data/data_conversion/scootch_sleeve_bdries.perl][scootch_sleeve_bdries.perl]]).  See Section [[harvest][harvest]] for details.







* DONE index computation on machines
<<indexing>>

1. Tar up the old version of the data, either locally or on lewis after
   rsyncing up.  Today's date is inserted into the archive name:

#+BEGIN_SRC sample tar command
$ pwd
../c/maize/demeter
$ tar cvf archival/db_data.31.7.2018.tar data/*.pl data/*.org
$ ls -lt archival/
total 88496
-rw-r--r--   1 toni  staff  45307904 Jul 31 13:54 db_data.31.7.2018.tar
drwxr-xr-x  11 toni  staff       374 Jul 22 08:05 obsolete_code
drwxr-xr-x  11 toni  staff       374 Jul 22 05:29 obsolete_data
drwxr-xr-x  17 toni  staff       578 May 18 18:57 16r_data_reconstructn
drwxr-xr-x  12 toni  staff       408 May 18 18:56 17r_data_reconstructn

#+END_SRC



2. bring these up to date:

   + make sure current_crop:current_crop/1 is up to date.

   + make sure current_inbred:current_inbred/5 is up to date:  copy the
     prior crop's facts, change the crop, and make sure parents are ok.

   + make sure inbreds listed in packing_plan.org are really the current
     inbreds!  check [[file:/athe/c/maize/demeter/data/genotype.pl][genotype.pl]] to be sure.

   + once these data are up to date, [[indexing][recompute indices]].
   


3. Recalculate indices using [[file:../../demeter/code/genetic_utilities][genetic_utilities:make_indices/0]].  Errors and
   crashes are likely to be from incomplete data, not bugs in the code.
   The most likely culprits are missing [[file:../../demeter/data/packed_packet.pl][packed_packet/7]], [[file:../../demeter/data/planted.pl][planted/8]],
   [[file:../../demeter/data/genotype.pl][genotype/11]], and [[file:../../demeter/data/harvest.pl][harvest/7]] facts.  Comment out any rows that were
   planted twice in [[file:../../demeter/data/planted.pl][planted/8]] before indexing, so no editing of
   [[file:../../demeter/data/planting_index.pl][planting_index/4]] facts or computing indices in two steps are needed.

#+begin_src prolog load_demeter as prior save state won't work on different machines
$ swipl
Welcome to SWI-Prolog (threaded, 64 bits, version 8.0.3)
....

1 ?- [load_demeter].

....
true.


2 ?- make_indices.
making barcode_index
making frpc_index
making planting_index
06N-[] 

06R-[] 
...
08R-[] 
starting crop_rowplant_index and row_members_index
Warning! StringOrAtom I105.1 is too large to pad to 5 in genetic_utiliies:pad/3
Warning! StringOrAtom I105.1 is too large to pad to 5 in genetic_utiliies:pad/3
...
Warning! StringOrAtom I112.4 is too large to pad to 5 in genetic_utiliies:pad/3
true 
.


3 ?- halt.
#+end_src



The code generates a barcode_index/7 fact from the barcode files of prior
crops using [[file:../../crops/scripts/make_barcode_index.perl][make_barcode_index.perl]].  *Iff the barcodes aren't on the machine
running the code*, then rsync down that directory and repeat [[file:../../demeter/code/genetic_utilities][make_indices/0]]:

#+BEGIN_SRC grabbing the barcodes directory
[kazict@lewis4-r630-login-node675 data]$ cd ../../barcodes/
[kazict@lewis4-r630-login-node675 barcodes]$ ls
06g  06r  07r  08r  10n  11n  12n  13r  15r  17r  19r        notes
06n  07g  08g  09r  10r  11r  12r  14r  16r  18r  inventory
[kazict@lewis4-r630-login-node675 barcodes]$ pwd
/gprs/pithos/c/maize/barcodes
[kazict@lewis4-r630-login-node675 barcodes]$ logout
Connection to lewis closed.

laieikawai:utilities toni$ pushd ~/me/c/maize/barcodes/
~/me/c/maize/barcodes ~/me/utilities
laieikawai:barcodes toni$ rsync -avucz kazict@lewis:/gprs/pithos/c/maize/barcodes/* .
#+END_SRC

This will probably take some time ;-).  The files are small, but there are
many of them.






4.  Check compilation of the data and make a new save state, which will
   have the updated indices.  You shouldn't have any syntax errors.  To
   make the save state,

#+BEGIN_SRC making the save state
$ pwd
../c/maize/demeter/code

$ swipl
.... messages ....

? - ['../data/load_data',set_demeter_directory],qsave_program('../data/saved_data').
.... messages ....
#+END_SRC



Then halt, load the saved data, and then load the code:

#+BEGIN_SRC load_code
$ ../data/saved_data

1 ?- [load_code].

#+END_SRC









* DONE pedigree computation
<<pedigrees>>

1. Run [[file:pedigrees.pl:check_status_branches/2][check_status_branches/3]], setting an appropriate threshold for the
   back-crosses to keep the field size reasonable, before going through the
   pedigrees to know which ones can be ignored (output is
   CROP/planning/[[file:../CROP/planning/status_branches.org][status_branches.org]]).  Sort the back-crosses in emacs to
   group related markers together.  

#+begin_src prolog
  % check_status_branches(+PlanningCrop:atom,+BCThreshold:integer,+File:atom) is semidet.
  
  % e.g., 
  
  check_status_branches('24r',5,'status_branches.org').  
#+end_src




2.  calculate current pedigress using [[file:../../demeter/code/pedigrees.pl][pedigrees:compute_pedigress/2]]:

Use the dpid switch to use the deconstructed numerical genotypes, which
avoids using the migratable family numbers.  

#+begin_src prolog
compute_pedigrees(dpid,'24r').
#+end_src
   

ascii output to ../c/maize/crops/CROP/planning/current_pedigrees/*/*.org 
pdf   output to ../c/maize/crops/CROP/planning/pdf_pedigrees     

The =org= files have links to the Nikon RAW NEF format images.  On my machine,
clicking the link triggers loading the image (perhaps converted to png?)
into the Mac's Preview App.  The NEF files can also be viewed in an Emacs
buffer, but this is quite a bit slower and more clumsy. <2022-02-15 Tue>


The PDF versions are automatically generated and copied to the [[file:~/Dropbox/corn/CROP/pdf_pedigrees][dropbox
pdf_pedigrees directory]] for manual analysis and transfer among platforms.




If warnings appear, these should be copied and pasted into
[[file:../CROP/planning/warnings][warnings]] for manual checking.


If you have to re-run the predicate, delete the output directories, /e.g./,:
#+BEGIN_SRC 
bash-3.2$ pwd
/Users/toni/me/c/maize/crops/20r/planning
bash-3.2$ rm -rf current_pedigrees/ pdf_pedigrees/ ~/Dropbox/corn/20r/pdf_pedigrees/

#+END_SRC


Make sure enscript is installed.  On the mac, the easiest way is homebrew:

#+BEGIN_SRC 
brew install enscript
#+END_SRC



#+begin_rmk <2021-04-18 Sun>
see pedigrees.pl:  output_checks throws an existence exception for the
Stream.  But I can't even figure out what calls it!  Ugh.  Pedigrees seem
to be computed fine on second try, though.
#+end_rmk




3. Revise the [[file:../data/branch_status.pl][branch_status/11]] facts to reflect the changes after each crop
   as the pedigrees are analyzed.  Revise [[file:../data/pedigree_tree.pl][pedigree_tree/2]] as needed.
   Outputting the pedigrees into subdirectories using the [[file:../data/pedigree_tree.pl][pedigree_tree/2]]
   facts relies on matching file names (*without extensions!*), so if the
   file is renamed due to a code change (for example to suppress silly
   characters), then the pedigree will end up in the "classify"
   subdirectory.  


   One can move pedigree files in the three output file directories after
   revising [[file:../data/pedigree_tree.pl][pedigree_tree/2]], but the simpler approach is to just recompute
   everything.


   Build a [[indexing][new save state]] and recompute current pedigress using
   [[file:../../demeter/code/pedigrees.pl][pedigrees:compute_pedigrees/1]] until the [[file:../data/branch_status.pl][branch_status/11]] and
   [[file:../data/pedigree_tree.pl][pedigree_tree/2]] facts are consistent with the pedigrees.



   
4.  In the past, it was very helpful to compare this crop's pedigrees with
    the last crop's.  Of course, the last crop's pedigrees won't have its
    offspring in the pedigree, so these must be ablated.  Follow directions
    in [[file:../scripts/ablate_crops_offspring.perl][ablate_crops_offspring.perl]] to do so. With changes in file names,
    this probably won't work anymore.


5.  Run the pedigree integrity checks.  One is to check for changes in gene
   and K number assignments along the pedigree.  This is now incorporated
   into the pedigree computation.  The other (someday) is to compute the
   pedigrees by crop and rowplant, rather than by unifying on the entire
   numerical genotype, and compare the two versions.
    


6. After analyzing the pedigrees, revise the data in [[file:../../demeter/data/branch_status.pl][branch_status/11]] to
   reflect progress.  This must be done by hand.  Also, follow up on any
   warnings issued by the pedigree integrity checks.  Rerun
   pedigrees:check_status_branches/3 to get the current state of the art.



7.  This may take a few iterations of fact-checking, index compilation,
    and pedigree building.  We may gain branches in our pedigrees, but we
    shouldn't lose any previous branches except for an extremely good
    reason.  The pedigree calculation is based on numerical genotypes, not
    symbolic ones, so misassignment of genes and K numbers, etc., shouldn't
    affect the results UNTIL we compute tags and the field book.  Then it
    will matter a lot.  At this stage, the worst that can happen is that a
    line is in the wrong place in the field.





* DONE crop planning (revised <2021-06-01 Tue>)

1. *MAKE THE MAP FIRST!* or early on, especially if there are skips,
   protectors, funny layouts, etc.  Once we have the field dimensions in
   rows and ranges, the map really helps with placing the odd rows (skips,
   protectors, /etc/.).  A spreadsheet is most convenient as this allows
   for coloring and boxing regions by type.


2. With the pedigrees and branches analyzed, write the [[file:../CROP/planning/packing_plan.org][packing_plan.org]]
   file.  This can be done /de novo/; generated from the prior crop's
   packing_plan.org file using [[file:../scripts/merge_plan_data.perl][merge_plan_data.perl]] and edited; or copying
   an earlier packing_plan.org file and editing that.


In choosing lines to plant, the following incantations are very useful
([[https://stackoverflow.com/questions/2258169/uniq-skipping-last-n-characters-fields-when-comparing-lines][unique trick]]):
#+BEGIN_SRC 

$ grep 1[34]R4089 inventory.pl | sort -k1,1 -t',' --stable --unique | grep -v B 
% grep 1[34]R4088 mutant.pl | sort | grep les

#+END_SRC



However this is done, the key elements are:
   + the experimental and management goals for that crop;
   + the tables for computing numbers of lines, inbreds, and stakes;
   + the packing_plan/9 facts, one for each row and half-row, embedded in
     org code blocks, e.g.,

#+BEGIN_EXAMPLE

#+begin_src prolog :tangle yes
packing_plan(,1,['09R201:S0xxxxxx','09R201:S0xxxxxx'],1,[inbred],'','',20,20).
#+end_src

#+END_EXAMPLE


3.  Edit the [[file:../CROP/planning/packing_plan.org][packing_plan.org]] file to represent what we really want to
    do. Remove the old crop header and leave just table stubs.  Note that
    there should be NO Crop argument in the packing_plan/9 facts at this point.

   + Insert the packing_plan facts between prolog source code blocks as
     these can be automatically tangled into source code.

   + Hand-correct cl and ft fields for inbreds, and other lines as needed.

   + Skip one line between sets, multiple lines between mutants.

   + If there are spreadsheet data from Gerry, convert them from Gerry's
     spreadsheet into packing_plan/10 by hand.  BE CAREFUL!  Not every row
     has a line in his spreadsheet, but does have a card in his field book.

   + Different types of lines can be counted by hand, by grepping and wc,
     or by using [[file:../scripts/count_lines.perl][count_lines.perl]] to compute the summary tables and
     generate [[file:../CROP/planning/line_counts.org][line_counts.org]] in the CROP/planning subdirectory.  Copy
     those tables into [[file:../CROP/planning/packing_plan.org][packing_plan.org]], straighten lines, and compute each
     table twice.








* DONE numbering rows

0. Once the packing_plan.org file is complete, export it to
   [[file:../CROP/planning/packing_plan.prolog][packing_plan.pl]] using C-c C-v t (see the [[https://orgmode.org/manual/Extracting-source-code.html#Extracting-source-code][orgmode export man
   page]]). This file will be used in the subsequent steps.




   
1. The input to [[file:../c/maize/crops/scripts/merge_plan_data.perl]] to number rows is:

packing_plan(,NumPackets,SetAlternativeParents,Plntg,CrossInstructns,SetInstructions,
                   KNum,Cl,Ft).

nb: no Crop argument, this will be inserted on generating row sequence
numbers.

#+begin_src
bash-3.2$ pwd
/Users/toni/me/c/maize/crops/23r/planning

bash-3.2$ pushd ../../scripts/
~/me/c/maize/crops/scripts ~/me/c/maize/crops/23r/planning ~/me/c/maize/demeter/data


bash-3.2$ ./merge_plan_data.perl sequence 23r 22r

# ignore the following whining:

Use of uninitialized value $front in concatenation (.) or string at ./merge_plan_data.perl line 272, <$cur_fh> line 226.
Use of uninitialized value $middle in concatenation (.) or string at ./merge_plan_data.perl line 272, <$cur_fh> line 226.
Use of uninitialized value $end in concatenation (.) or string at ./merge_plan_data.perl line 272, <$cur_fh> line 226.
Use of uninitialized value $front in concatenation (.) or string at ./merge_plan_data.perl line 272, <$cur_fh> line 227.
Use of uninitialized value $middle in concatenation (.) or string at ./merge_plan_data.perl line 272, <$cur_fh> line 227.
Use of uninitialized value $end in concatenation (.) or string at ./merge_plan_data.perl line 272, <$cur_fh> line 227.
Use of uninitialized value $front in concatenation (.) or string at ./merge_plan_data.perl line 272, <$cur_fh> line 228.
Use of uninitialized value $middle in concatenation (.) or string at ./merge_plan_data.perl line 272, <$cur_fh> line 228.
Use of uninitialized value $end in concatenation (.) or string at ./merge_plan_data.perl line 272, <$cur_fh> line 228.
.....

#+end_src


2. run  [[file:../c/maize/crops/scripts/merge_plan_data.perl][merge_plan_data.perl]] on [[file:../CROP/planning/packing_plan.prolog][packing_plan.pl]] /in sequence mode/ to
insert row numbers and Crop argument.

call is:

#+BEGIN_SRC 
./merge_plan_data.perl sequence CURRENT_CROP PRIOR_CROP
#+END_SRC


nb: Check to be sure all the packing_plan/9 facts have made it through!
When editing the packing_plan.org file, it's easy to forget a code block
statement or have a syntax error in a fact that prevents parsing.  A good
way to check is to 


#+BEGIN_SRC 
grep packing_plan packing_plan.org > pp
#+END_SRC

edit pp to remove extraneous lines; edit packing_plan.prolog to remove
blank lines; and then diff and wc the two files against each other.

3. Make sure the periods at the end of each clause are present:  for some
   reason emacs isn't exporting these <2022-05-22 Sun>.  Unterminated
   clauses will produce an "Syntax error: Unexpected end of file" error. I
   fixed the obvious bug in merge_plan_data.perl but there may be others.


* DONE packing and planting


** packet labels and plan


Ideally, one uses the file generated by prolog.  But it may be necessary to
generate labels directly from sequenced.packing_plan.pl using perl (see
below).

Complicated fields (/e.g./, those with skips and protector rows) need a map
during planning to adjust sequence numbers of the packets.


*** DONE prolog-based procedure to generate packets and plan


1. move [[file:../CROP/planning/sequenced.packing_plan.pl][sequenced.packing_plan.pl]] to [[file:../CROP/planning/packing_plan.pl][packing_plan.pl]].


2. [[indexing][After bringing data, indices, and saved state up to date]], use
   [[file:../../demeter/code/pack_corn.pl][pack_corn:pack_corn/1]] to generate plan/6, packet labels, and rows
   sequence labels.  Include the inbreds, skips, and shade rows so that
   every packet has the correct row number.

   + don't forget to make the /barcodes/CROP, CROP/management, and
     CROP/tags directories first!

   + input to pack_corn/1:

#+begin_src prolog :tangle no

packing_plan(RowSequenceNum,NumPackets,
                   SetAlternativeParents,Plntg,CrossInstructns,SetInstructions,
                   KNum,Crop,Cl,Ft)

#+end_src



   + failure producing back-tracking signals a syntax error, usually in the
     SetAlternativeParents.  An easy way to find these:

#+begin_src prolog
1 ?- [demeter_utilities].
true.

2 ?- ['../../crops/21r/planning/packing_plan.pl'].
true.

3 ?- findall(List,(packing_plan(Row,_,List,_,_,_,_,_,_,_),\+length(List,2)),L),write_list(L).
[20R405:M0005009,20R4810:0017701] 
L = [['20R405:M0005009,20R4810:0017701']].

#+end_src

*Correct these in the packing_plan.org file, then merge_plan_data and mv to packing_plan.pl!*


3. *Predicate will fail if harvest facts absent!*  Also, a change in family
   or K numbers between inventory, genotype, and the packing plan will
   cause the predicate to fail.





*** DONE perl-based procedure for just the packet labels

1.  Use [[file:../scripts/make_seed_packet_file.perl][make_seed_packet_file.perl]] to generate the packet data for
    packing seed from the [[file:../CROP/planning/sequenced.packing_plan.pl][sequenced.packing_plan.pl]] file.  This latter
    file was generated by [[file:../scripts/merge_plan_data.perl][merge_plan_data.perl]] using operation sequence.
    The output is the [[file:../CROP/planning/seed_packet_labels][seed_packet_labels]] file, which is input to
    [[file:../../label_making/make_seed_packet_labels.perl][make_seed_packet_labels.perl]]. 


2.  The script assumes a single parental line is already correctly chosen
    for packing.  Changes to this plan can occur in the seed room due to
    incorrect inventory counts, poor kernel state, or apparent defective
    kernels.  For this reason, the actual packed_packet data are the final
    authority. 


3.  The script [[file:../scripts/make_seed_packet_file.perl][make_seed_packet_file.perl]] now includes the
    current inventory sleeve for each packet.  There is a bug in
    constructing the %inventory, however. <2019-06-02 Sun>  Bug corrected
   --- the problem was in parsing ``sleeve'' z00000 for the infinite
   amounts of elite and skipped corn.  Fixed, <2019-09-08 Sun>.



4.  The packets must be re-ordered into inventory or packing order
    manually before generating the actual labels.  The trial algorithm in
    crop_management.pl is incorrect, but new algorithm in
    [[file:../../data/data_conversion/update_inventory.perl][update_inventory.perl]] is correct (multidimensional hash of hashes!).


      + mutants, sorted by crop, and then by type, and then rowplant within type.

      + inbreds, sorted by type, and then by row (planting usually will do fine).

      + then new accessions, which are filed in box0.



5. Ensure [[file:../CROP/{management,tags}][{management,tags}]] and [[file:../../barcodes/CROP][barcodes/CROP]] subdirectories exist.


*** DONE printing the packet labels for either Prolog or Perl procedures

1. Sort the  [[file:../CROP/planning/seed_packet_labels][seed_packet_labels]] file by hand as needed for convenience in
   packing.  *THIS SHOULD NO LONGER BE NECESSARY, <2024-05-17 Fri>*.

2. Ensure [[file:../../barcodes/CROP]] subdirectory exists.  

3. For both the Prolog and Perl approaches, run
   [[../../label_making/make_seed_packet_labels.perl][make_seed_packet_labels.perl]] to generate the stickers and print on the
   Avery 1 x 2 5/8 inch 30-up labels (Avery 5160).

#+begin_src 
bash-3.2$ pushd ../../../label_making/
~/me/c/maize/label_making ~/me/c/maize/crops/23r/planning ~/me/c/maize/demeter/data


# adjust directories in ../../label_making/make_seed_packet_labels.perl
# using incremental search and replace to change to the current crop

bash-3.2$ ./make_seed_packet_labels.perl 
i: ../crops/23r/management/seed_packet_labels.csv
o: ../crops/23r/tags/packet_labels.tex
b: ../barcodes/23r/
(,,,,,,,,,)
(p00010,705,23R705:F0000000,23R705:F0000000,20,20,v00000,1,136,2)
....

#+end_src







** packing

1. Pack corn, generating packed_packet/7 facts from packed_packet.csv using
   [[file:../../data/data_conversion/convert_data.perl][convert_data.perl]].  Check carefully for any missing packing_plan facts
   as these will cause the packet to be missed.  Poor overhead lighting in
   the seed room can produce scanning errors. The facts for packets that
   are repacked because the corn didn't germinate, the packet got wet, or
   some other anomaly should be commented out if the field was also
   rearranged from the initial plan and a new field arrangement must be
   computed from [[file:../../demeter/code/genetic_utilities.pl][genetic_utilities:reorganize_plan/3]].




2. Pack the corn.  Students can pack inbreds relatively unsupervised ---
   one {person,team}/inbred/bench!  Using the new [[file:../../equipmt/counting_pan/IMG_9049.JPG][counting pan]] sure speeds
   things up.

   + :toni: and experienced students pack mutants, but they can have help
     fetching and scanning. 

   + after packing and conversion of data to Prolog, grep out packet facts
     into [[file:/athe/c/maize/CROP/management/all_packed_packets.org][an org file]], order the packets by number, and check that each
     number is 1 more than the previous one.  Run down missing numbers and
     insert facts manually into [[file:/athe/c/maize/demeter/data/packed_packet.pl][packed_packet.pl]], and check that packets
     are really present in the seed to be planted.


** row stake manufacture <2020-06-03 Wed>

1. Inventory the stakes, replacing missing ones or those that are too
   short.  The easiest way is to open each bag, lay the stakes against a 2
   x 4 in numerical order, and then look.  Rebundle each bag's stakes in 1
   -- 20 stacks with a rubber band and slip the bag label into a stack.
   For each bag of stakes, record the stakes needed, the bag number, and the
   starting and finishing stakes of the bag.  Export to csv and thence to
   org. 

2. For stakes that have lost their labels but are still useable, lever up
   the staples on one side after unbending them, then twist out by grabbing
   them with a pair of pliers.

3. Figure out which stakes are needed and assemble a list like that in
   [[file:../inventory/management/20r_stakes][20r_stakes]].

4. Run [[file:../../label_making/make_vertical_row_stake_labels.perl][make_vertical_row_stake_labels.perl]].  This year's version changes
   the call to include the name of the crop in which the stake is
   manufactured and the material used for the label, so check the call.
   Make sure the file ends in 000 to ensure all the useful tags are
   printed.  Probably we need as many of those 000s as we have unfilled
   gaps on the sheet.

#+begin_src 
$ pwd
/Users/toni/me/c/maize/label_making

./make_vertical_row_stake_labels.perl i r 23r 'polyes'
#+end_src   

5. Print the stakes on a laser jet printer.  Ideally the printer is set for
   heavy cardstock, uses tray 1, and a straight through paper path.
   Printing from tray 2 to the bin out the back seems to work too.

   The 20r, 21r, 22r, and 23r stakes used a 7 mil polyester sheet from MfM
   with the printer set to transparency.  Warm up the printer with other
   print jobs first.

   The 24r stakes used plain recycled paper and then were laminated.  The
   layout was adjusted to be more bifocal-friendly <2024-05-17 Fri>.

6. Staple labels to the stakes using T50 galvanized staples, 12--15mm,
   pounding the ends so they are folded over.  Rubber band consecutive
   bundles of 20 (a rubber band at the top and bottom of each stack) and
   return to labelled stake boxes, ready for planting.


** planting


1. Lay out field using four tape measures to get the corners square
   enough.  *OR use the measuring wheel!*

2. If soybeans, cover those rows with black paper until after Chris has
   sprayed with herbicide, then plant.

3. Plant corn, recording and generating planted/8 facts. These must be
   confected for the winter nursery from the work order spreadsheet, since
   they don't scan the packets or stakes!

4. Use hand jab planters for experimental corn until the Jang TD1 and maize
   rover are thoroughly tested.  It's fine for borders and elite protecting
   dainty lines (Les15, Les20, lls).

5. When using the Jang, measure directly the depth of the furrow made by
   the drill (don't trust its gauge); push the Jang, and especially its
   back wheel, /downwards into/ the soil to firm the soil over the seed.
   When this is done, there is no need to firm the soil by foot pressure,
   as we do with the jab planter.  As with the jab planter, a deeper depth
   mitigates bird damage.

6. Wait to place the twinkle tape until after Chris has sprayed with
   herbicide.  Leave it up until the seedlings have several leaves.




* GNG making the plan/6 facts


** TODO write code to retrospectively and prospectively clean up plan/6 facts! <2020-07-14 Tue>

See [[file:../../demeter/code/genetic_utilities.pl][genetic_utilities:filter_prior_crop_data/6]] for outline of regexes needed.


** DONE Prolog-based /de novo/ plan/6 generation

[[file:../../demeter/code/pack_corn.pl][pack_corn:pack_corn/1]] generates new [[file:../../demeter/data/plan.pl][plan/6]] facts and appends these to the
file for each crop.  The revised version incorporates old plans and
comments into the current comments derived from the [[file:../CROP/planning/packing_plan.org][packing_plan.org]] file
in its various incarnations.


These facts can be amended as needed directly in the file.


nb:  Family numbers ARE NOT INCLUDED IN THE PLAN FILE, so amendments to 
accommodate migration of family numbers are not needed.



** DONE Perl-based merging previous plans

Run [[file:../scripts/merge_plan_data.perl][merge_plan_data.perl]] in operation merge to
fuse the prior year's packing_plan.pl and last year's final plan
information, stripping out row number and crop identifier.

call is perl ./merge_plan_data.perl merge  CURRENT_CROP PRIOR_CROP









* DONE field book production
<<fieldbk>>


I need to amend the field book code (from planted.pl):

% we planted corn in the skipped rows on 24.7 to compensate for the hail
% damage of the leaves.  I have commented out these skipped rows so that
% the field book will compute properly.
%
% I will have to amend the field book computation to take the most recently
% planted value if that row was previously skipped.
%
% Kazic, 18.10.2023    



1.  Recompute the indices after planting is finished (see [[indexing]] above).
    [[file:../../demeter/data/planting_index.pl][planting_index/4]] gives what was actually planted in each row,
    simplifying flagging any revisions needed to the anticipated plans.

    It can happen that family numbers are changed, or different seed packed
    than what was planned, or there are scanning errors during packing,
    between the time the packing_plan.org file is written and the corn is
    planted.  By showing what was actually planted in the most
    contemporaneous packet packed, [[file:../../demeter/data/planting_index.pl][planting_index/4]] helps pin down these
    discrepancies for resolution.  The [[file:../../demeter/data/genotype.pl][genotype/11]] facts rule: usually the
    packed_packet facts will be ok, but the two packing_plan files may need
    editing to get everything to jibe.

    This especially applies to the plan/6 facts, which rely on the
    numerical genotypes to find the plans.


2.  Run [[file:../../demeter/code/analyze_crop.pl][make_field_book/2]] on all remedied data, reindexed and stored in a
    new save state.  This makes a nice file, now suitable for ipad and
    iphone6.  This requires either packing_plan/10 facts or the plan/6
    facts.  The file is automatically pushed to the designated Dropbox
    directory. 

#+BEGIN_SRC load the old data
$ ../data/saved_data 
#+END_SRC

#+begin_src prolog recomputing the indices and field book as plans and observations change




%%%%% make sure crop/7 is current; ok to guess the harvest dates %%%%%%%




% do this first if indices need to be recomputed

#+begin_src 
$ swipl
?- [load_demeter].
?- make_indices,halt.





% do this every time the plan/6 facts are modified, but no indices need to be recomputed


$ swipl

?- ['../data/load_data',set_demeter_directory],qsave_program('../data/saved_data'),halt.


$ ../data/saved_data



%%%%% delete older versions of the plan for a particular crop when computing the field book %%%%%%%

?- [load_code,analyze_crop].
?- make_field_book('24R',field_book),halt.
#+end_src


    *If there is no genotype/11 fact for a line, a warning will be issued*
    *and the line's row(s) will not appear in the field book!*  Hence
    iteration between field book and construction of genotype/11 facts is
    needed.


    The plan/6 facts may have incorrect markers or K numbers compared to
    the packing_plan file.  This happens through mis-identification of the
    marker in the genotype/11 facts.  Correct, make a new save state, and
    check again.

    [[file:../../demeter/code/analyze_crop.pl][make_field_book/2]] should be run each time there are new observations or
    plans to be incorporated into the plan/6 facts (see below for summary).

    Someday add automatically generated cut-down jpegs of images . . .



3.  As the plan is amended during the season, make a new save state:
#+begin_src prolog incantation
bash-3.2$ swipl
?- ['../data/load_data',set_demeter_directory],qsave_program('../data/saved_data').
#+end_src

recompute the indices (just in case):

#+begin_src prolog indices
2 ?- [genetic_utilities].
3 ?- make_indices.
#+end_src

and recompute the field book.




4.  If needed, independently check prolog field book by running
    crops/check_row_assignments.perl.  It gives the planting number, which
    is useful. (obsolete?)




* DONE generation of new family numbers, genotypes, and plant tags

** command synopsis

Briefly,


   + make sure [[file:../../demeter/data/priority_rows.pl][priority_rows/2]] is current (and all data and indices,
     including the plan/6 facts)

   + make sure [[file:../../demeter/data/row_status.pl][the stand count data]] are current --- otherwise
     generate_plant_tags_file/3 won't terminate


#+begin_src prolog checking that priority_rows/2 is complete
	    
?- [crop_management,genetic_utilities].
	    
	  
% hmmm, gotta fix these
Warning: /Users/toni/me/c/maize/demeter/code/crop_management.pl:1523:
	Singleton variable in branch: Prefix
Warning: /Users/toni/me/c/maize/demeter/code/crop_management.pl:1633:
	Singleton variable in branch: ScoringDate
Warning: /Users/toni/me/c/maize/demeter/code/crop_management.pl:2134:
	Singleton variable in branch: Inbred
  
      
    
?- all_rows_accounted_for('24R').
	    
	    
Hooray! all inbred and mutant rows are in the list for tags

true.
#+end_src

   + generate the plant tags file






#+begin_src prolog 
  ?- [load_code,crop_management].
  
  % ... warnings ....
  

  ?- generate_plant_tags_file('24R','fgenotype.pl','plant_list.csv').
  
#+end_src


   + iterate over [[fieldbk][make_field_book/2]] and generate_plant_tags_file/3 once the
     fgenotype/11 facts are checked and confirmed, then integrated into
     genotype/11.


   + generate the tags


#+BEGIN_SRC generating the tags
$ cd ~/me/c/maize/label_making
$ ./make_plant_tags.perl 23r test   {go,q}   (test first, then go or q; for now ignore the warning, see comments in code)


# if switch was not go:

$ cd ../crops/CROP/tags
$ latex prioritized_tags
$ dvips prioritized_tags

#+END_SRC

   + <2024-07-08 Mon> Preview no longer supports postscript files.  I thought ps2pdf smudges
     the barcodes, but maybe not.  Turns out there are a lot of possible
     switches ([[https://web.mit.edu/ghostscript/www/Ps2pdf.htm][man page]]). [[https://acrobatusers.com/forum/printing-prepress/distiller/][Acrobat Distiller prepress]] setting seems to be
     [[https://helpx.adobe.com/acrobat/using/pdf-conversion-settings.html][what we want]] (no downsampling of monotone images, image resolution is
     300 dpi, bicubic downsampling, resolution 1200 dpi).  It runs really
     quickly, much faster than Preview used to!  [[https://files.lfpp.csa.canon.com/media/Assets/PDFs/TSS/external/DPS400/Distillerpdfguide_v1_m56577569830529783.pdf][Adobe parameter
     documentation]] includes information on AutoRotatePages.

   #+begin_src 
   ps2pdf -dProcessColorModel=/DeviceGray -dPDFSETTINGS=/prepress -dAutoRotatePages=/All manual.prioritized_tags.ps manual.prioritized_tags.pdf
   #+end_src

   and file size is a little smaller:

   #+begin_src 
bash-3.2$ ls -l *prio*pdf
-rw-r--r--@ 1 toni  staff  10257089 Jul  8 20:13 def.manual.prioritized_tags.pdf
-rw-r--r--@ 1 toni  staff  10253773 Jul  8 20:40 manual.prioritized_tags.pdf
   #+end_src


** important details and gotchas




If lines that were not previously planted are planted in the current crop,
then their families and genotypes will not have been assigned.  So run
[[file:../../demeter/code/crop_management.pl][crop_management:generate_plant_tags_file/3]] to get the new family numbers
and tentative fgenotype/11 facts; manually revise the fgenotype/11 facts
into genotype/11 facts; make a new save state of the data; and re-compute
the tags.  The fgenotype/11 facts are appended to the end of [[file:../../demeter/data/genotype.pl][genotype.pl]]:
revisions occur in that file.





Several iterations may be needed to ensure all new lines have genotypes.
At the end, there should be no new family numbers assigned, though some
warnings may persist (but shouldn't).  

*Only when all genotypes have been assigned will the full field book be correctly computed.*

Mutant family numbers are issued consecutively, beginning with the last
mutant line added.  No gaps in numbers due to retirement of the fact are
filled in,  no numbers are reused, and a line receives only one family
number, no matter how many rows of it are planted in the same crop.


[[file:../../demeter/code/crop_management.pl][crop_management:generate_plant_tags_file/3]] assumes a list of rows in order
of priority for some action requiring tags ([[file:../../demeter/code/priority_rows.pl][priority_rows/2]]).  For us,
these actions are photography and pollinations.  This list is compiled by
walking around the field and assessing the plants.  The rows are grouped
first by priority category, and then ordered by row number for easier
tagging.  There can be gaps in the row numbers, but all rows that should
eventually be tagged should be represented, since the tags file is printed
and sawn only once.





[[file:../../demeter/code/crop_management.pl][crop_management:generate_plant_tags_file/3]] generates [[file:../CROP/management/plant_list.csv][the plant_list.csv]] in
the appropriate CROP/management directory.  This file is then processed with
[[file:../../label_making/make_plant_tags.perl][make_plant_tags.perl]] to produce the tags file for printing.  I have
separated the two steps, rather than calling the perl script from the
prolog, so it is easier to fix problems.  The output file
[[file:../CROP/tags/prioritized_tags.ps][prioritized_tags.ps]] file appears in the CROP/tags directory.  This file
should be opened in Preview or other postscript reader, checked for obvious
errors, and then /printed in landscape mode to US legal size (8.5 x 14") as
a pdf/. 


The pdf file is then taken to Fedex for printing on 100 lb 11 x 17" matte
cardstock.  The sheets are cut to legal size and the tear-off tags
perforated after printing.  The resulting block of tags is then taken to
the machinist for drilling and sawing.  It usually takes Fedex several days
to print, cut, and perforate the tags: allow a week, as they may not have
sufficient cardstock and have to order more (a slow and error-prone
process).  Perforation is the slow step, since each sheet must be
individually done (unless they're shipped to a location that has a
perforating machine).  Ensure that the wide perforations --- ca. 1 mm space
between holes --- is used, not the microperforations.  These tear off too
easily in a breeze, scattering tags.  Waterproof paper is unncecessary.


Yes, it's possible to re-use the sheets if they were printed incorrectly
<2015-08-05 Wed>. 


When looking at the block with the printing down, the right-most column of
tags is numbers 1 (upper) and 2 (lower); the next is 3 and 4, etc.  Usually
the block must be divided in half to fit in the fixture for sawing, with a
pink sheet inserted at the division.  Holes for the pins are drilled first
at the top edge.  Then the blocks are sawn and racked on the pins,
rubber-banded, slipped into numbered tassel bags, rubber-banded again, and
put in the tag box.  Thus, the machinist receives:
   + the tag block;
   + 32 or more thick rubber bands;
   + 16 pins;
   + 16 numbered blocks to stop the pins;
   + 16 numbered tassel bags;
   + all in the tag box.


Allow at least a week for the machinist to drill and saw the tags.












* DONE post-planting data collection

** stand counts
  
Collect [[file:../../demeter/data/row_status.pl][row_status/7]] facts for stand counts, confecting if necessary for
winter nursery.

   + It is extremely important to accurately collect these data!

   + I modified the [[file:../../data/data_conversion/convert_row_status_data.perl][code]] to take a default average leaf number and to let
     us omit categories with zero counts (except for num_emerged) on
     <2022-07-04 Mon>.  Finally wrote code to ignore empty rows on
     <2024-07-08 Mon>, but haven't tested it yet.

   + We decided in 22r it's easier and faster to go by files, rather than
     ranges.  Start at the soggiest side of the field and work up to higher
     ground, in case rain or irrigation intervene.  Three people are ideal
     --- one scans, one records, and all look.
     
   + Go through the field systematically, looking at every row, each time.
     When we've just looked at rows that were empty and skipped around, we
     had a lot of missing data!

   + Two people are better at this job, one to count and call out the
     result, and the other to record.  WALK DOWN THE ROW --- do not rely on
     standing at one end of the row and eyeballing!  Even baby plants hide
     behind each other.  Beats me how they do it, but they know you are
     looking at them and duck.


** scoring

   + [[indices][recompute indices]] and make a [[save_state][new save state]] that incorporates the
     latest row scoring data
   + compute those yet to do:

#+begin_src prolog
$ ../data/saved_data

?- [load_code,crop_management].

% cranky singleton errors in the latter



% compute scoring status
?- find_rows_to_score('24R','../../crops/24r/management/rows_to_score').

93 rows scored so far
67 rows still to score

true 
#+end_src

   + *nb: this list excludes rows that have been scored 0 and that I want
     to revisit, and other rows marked for revisiting in the csv file!!!*


* GNG prefilling the mutant table

Recalculate the indices and make a new save state:

#+begin_src prolog
swipl
[load_demeter].
make_indices,halt.

swipl
['../data/load_data',set_demeter_directory],qsave_program('../data/saved_data'),halt.



../data/saved_data
[load_code,crop_management].

.... error messages from crop_management.pl ....
					 
prefill_mutant_table('24R'),halt.
#+end_src

output is in ~/Dropbox/palm/raw_data_from_palms/CROP/proto_mutant.csv


Set formats correctly in proto_mutant.numbers, temporarily shift the
datetime column in the raw.mutant table, add any needed rows, and copy the
prototype table into the raw.mutant table.  Shift the datetime column back
to the correct place, just before the observer column.


* DONE harvest <2020-09-01 Tue>
<<harvest>>



1. First clean any uncleaned data files.  Common errors are:
   + incomplete plant IDs (usually because tags wouldn't scan).  Keep track
     of these in [[file:/athe/c/maize/crops/CROP/management/tags_needed]] to
     simplify the task of filling in the first part of the string and
     generation of extra tags.
   + incorrectly formatted dates:  should be MM/DD/YYYY HH:MM:SS
   + missing data, such as image numbers or tissue tags
Then remove the emacs squiggle files.


2. Then compute harvest plan using [[file:../scripts/make_harvest_plan.perl][make_harvest_plan.perl]] (the one in crops/scripts!):
#
#+BEGIN_SRC computing the harvest plan

./make_harvest_plan.perl 24r 21 {test,go,q}

#+END_SRC
#
The second argument, "days out", is the number of days the desired harvest
date is from the day the harvest plan is computed.  If the PATH environment
variable is correctly set and enscript and ghostscript are installed (see
Section [[swinst]]), pdfs of the harvest plan and the day's work plan will be
generated.


It's nice to adjust the [[file:../../label_making/Typesetting/DefaultOrgztn.pm][color coding of the onion and mesh bags]] used for
harvest to avoid inadequate supplies (array bags in the file).  Just grab
the type and number of ear columns from the ASCII version of the harvest
plan, add them, and adjust the color coding as needed.



3. Now harvest the corn as you usually would, remembering to scan each
row's stake as it is harvested so the harvest dates are recorded and those
rows are removed from the plan.  It's a good idea to recompute the plan
during harvest to help ensure nothing is left behind.


Label the onion bags with TWO tags --- a numbered tag and a letter tag
indicating the type of corn in the bag.


4. Run [[file:../../data/convert_data.perl][convert_data.perl]] on the cleaned data for [[file:../../data/palm/raw_data_from_palms/CROP/*eta/*/row_harvested.csv][row_harvested.csv]] and 
[[file:../../data/palm/raw_data_from_palms/CROP/*eta/*/harvest.csv][harvest.csv]].  [[file:../../data/palm/raw_data_from_palms/CROP/*eta/*/row_harvested.csv][row_harvested.csv]] data are collected at the time of harvest
and [[file:../../data/palm/raw_data_from_palms/CROP/*eta/*/harvest.csv][harvest.csv]] when shelling corn.  After the crop has been filed, collect
[[file:../../palm/raw_data_from_palms/*/*eta/*/sleeve_bdry.csv][sleeve_bdry.csv]] data on the new corn to produce [[file:../../demeter/data/sleeve_bdry.pl][sleeve_bdry.pl]].


The code inserts the harvest dates into the [[file:../../demeter/data/harvest.pl][harvest/7]] facts.  [[file:../../label_making/Typesetting/MaizeRegEx.pm][MaizeRegEx.pm]]
may need revision to accommodate new note abbreviations, so check both raw
and test output data carefully before running [[file:../../data/convert_data.perl][convert_data.perl]] in mode
"go".


4. Run [[file:../../data/data_conversion/update_inventory.perl][update_inventory.perl]], scootching sleeve boundaries
   ([[file:../../data/data_conversion/scootch_sleeve_bdries.perl][scootch_sleeve_bdries.perl]]) if older inventory has been compressed.
   Corn is now sorted automatically into inventory order and sleeve numbers
   inserted from [[file:../../demeter/data/sleeve_bdry.pl][sleeve_bdry.pl]].


* GNG need a [[file:../c/maize/crops/scripts/migrate_family_numbers_in_demeter.perl][script to correct family numbers from X to Y in the non-genotype data]] as new mutants are discovered <2022-01-25 Tue>
  <<fam_num_sc>>


Because I suddenly mis-understand the problem, have decided to compute the
pedigrees first and go through them, <2022-01-30 Sun>
  
** goal

Need a script to migrate family numbers from X to Y in the non-genotype
facts in demeter.

** why

As new families arise from old ones due to newly recognized mutants, the
data obtained using the old family numbers become obsolete.  The newly
recognized line becomes a founder, but the data linked to the old family
number need to be revised accordingly.


For example, take family 4465 which became family 704 on 17.8.2021.
#+begin_src
$ pwd
/Users/toni/me/c/maize/demeter/data
 
$ grep -n 4465: *.pl | grep -v safe | grep -v index | grep -v missing | grep -v '%' | wc
#+end_src
returns 43 entries across the data, excluding the commented-out genotype/11 fact 


** raw materials in other code

Some of the ideas --- for example, a conditional --- are shown in
[[file:../../data/data_conversion/convert_cross_prep_data.perl][convert_cross_prep_data.perl and convert_cross_data.perl]]


** outline of code
<<migratn-code-outline>>

[x] Manually compile a list of old families -> new families by going through
  [[file:../../demeter/data/genotype.pl][genotype.pl]].  Save these as an appropriately commented perl hash in the
  script file directly.  Not as clean but damn if I can't get it to work
  otherwise. 

[] Make sure family numbers aren't reused! HOW?

Easiest is probably just grep.  But I think I don't understand the problem
now <2022-01-30 Sun>:

#+begin_src 
bash-3.2$ pwd
/Users/toni/me/c/maize/demeter/data

# oops

bash-3.2$ grep -n "genotype(1109," genotype.pl
1787:genotype(1109,201,'07R201:S0000101',2354,'07R2354:0040306','Mo20W','Mo20W','Mo20W','Les4',['Les4'],'K0303').
bash-3.2$ grep -n "genotype(1155," genotype.pl
1833:genotype(1155,200,'06R200:S00I1911',76,'06R0076:0007616','Mo20W','Mo20W','{+|les*-N1450}','{+|les*-N1450}',['les*-N1450'],'K7616').


# oops again

bash-3.2$ grep -n "genotype(1159," genotype.pl
1837:genotype(1159,300,'06R300:W00I4214',84,'06R0084:0008414','W23','W23','{+|Les*-N2397}','{+|Les*-N2397}',['Les*-N2397'],'K8414').
bash-3.2$ grep -n "genotype(4477," genotype.pl
6091:% genotype(4477,305,'15R305:W0000908',4373,'15R4373:0007409','W23','W23','M14','les23',['les23'],'K16306').



# what did 4477 turn into?

bash-3.2$ grep -n "genotype(4477," genotype.pl
6091:% genotype(4477,305,'15R305:W0000908',4373,'15R4373:0007409','W23','W23','M14','les23',['les23'],'K16306').
bash-3.2$ grep -n "genotype(703," genotype.pl
1392:genotype(703,405,'14R405:M0001302',4251,'14R4251:0018805','W23','W23','M14','Les*-tk1',['Les*-tk1'],'K70309').    




# ah, ok, this 704 is the descendant of 4231; but who are its descendants?

bash-3.2$ grep -n "genotype(4231," genotype.pl
5759:genotype(4231,4065,'13R4065:0014707',4065,'13R4065:0014707','Mo20W','{Mo20W|les23}','Mo20W','{Mo20W|les23}',[les23],'K1802').
bash-3.2$ grep -n "genotype(704," genotype.pl
1420:genotype(704,205,'15R205:S0000501',4231,'15R4231:0009207','Mo20W','Mo20W','{les23|Les*-tk2}','{les23|Les*-tk2}',['Les*-tk2'],'K70404').
1422:% genotype(704,4465,'16R4465:0004111',4465,'16R4465:0004111','Mo20W','Mo20W','Mo20W','Les*-tk2',['Les*-tk2'],'K70404').



#+end_src

  

[x] Read into a hash using old family as key.  

+ For each old family, grep all non-index files to find where these facts
  live and compile an array of those file names.  Unique this list as we
  are going to search for and correct all old families in that file in one
  pass. 

+ For each file:
  + initialize a new version of the file with a suitable header
  + read the old file into the new version until an old family is
    encountered (want to check for all hash keys in regex; can use alternation).
  + For a matching key, grab its value (the new family).
  + Insert a comment at that place in the new file, insert a commented out
    version of the original fact, insert the revised fact, and then proceed
    to the next hit.
  + Then close the file.


* obsolete

** emergency plant tag and field book production


#+begin_rmk


<2014-06-19 Thu> :toni:

Trito needs to be shut down as the air conditioner is leaking, so we are
going to confect data for the second and third plantings, and the
row_status facts, then compute.  I've already fixed the family number
re-use problem.


#+end_rmk


** to confect planted/8 and row_status/7

. grepped second and third planting from sequenced.packing_plan.pl, which
has row numbers and ma and pa

. wrote clean_data:confect_planting_n_stand_count_data/4, which confected
dummy row_status facts for all planted and unplanted corn, and planted/8
facts for unplanted corn in the second and third plantings.


. sorted data in output file and appended, with appropriate comments, to
planted.pl and row_status.pl


. recomputed indices, plant tags, and field book per usual.  BUT we
discovered the directions needed a little work!



** buried under making harvest plan


#+BEGIN_SRC safe file deletion
 ls *eta/*/*~
eta/1.9/cross.csv~              eta/27.8/cross.csv~             zeta/15.8/tissue_collectn.csv~
eta/13.8/cross.csv~             eta/27.8/cross_prep.csv~        zeta/16.8/plant_fate.csv~
eta/15.8/cross_prep.csv~        eta/27.8/plant_anatomy.csv~     zeta/17.8/image.csv~
eta/16.8/cross_prep.csv~        eta/27.8/plant_height.csv~      zeta/20.8/image.csv~
eta/18.8/cross.csv~             eta/3.9/cross.csv~              zeta/20.8/mutanta.csv~
eta/18.8/cross_prep.csv~        eta/30.8/cross.csv~             zeta/21.8/mutanta.csv~
eta/20.8/cross_prep.csv~        eta/30.8/cross_prep.csv~        zeta/23.8/image.csv~
eta/21.8/cross.csv~             eta/30.8/plant_anatomy.csv~     zeta/23.8/mutanta.csv~
eta/21.8/cross_prep.csv~        eta/30.8/plant_height.csv~      zeta/25.8/tissue_colectn.csv~
eta/23.8/cross.csv~             eta/31.8/cross.csv~             zeta/26.8/leaf_alignmt.csv~
eta/23.8/cross_prep.csv~        eta/31.8/cross_prep.csv~        zeta/26.8/mutanta.csv~
eta/24.8/cross.csv~             zeta/11.8/image.csv~            zeta/27.8/tissue_collectn.csv~
eta/24.8/cross_prep.csv~        zeta/11.8/tissue_collectn.csv~  zeta/7.8/plant_fate.csv~
eta/24.8/tissue_collectn.csv~   zeta/12.8/mutanta.csv~          zeta/8.8/image.csv~
eta/25.8/cross.csv~             zeta/12.8/plant_fate.csv~       zeta/8.8/plant_fate.csv~
eta/25.8/cross_prep.csv~        zeta/13.8/image.csv~            zeta/8.8/tissue_collectn.csv~
eta/26.8/cross.csv~             zeta/15.8/image.csv~
eta/26.8/cross_prep.csv~        zeta/15.8/plant_fate.csv~

bash-3.2$ ^ls^rm
rm *eta/*/*~

#+END_SRC


.  Now read the data into prolog.

#+BEGIN_SRC 
$ cd ../../data_conversion/
$ pwd
/athe/c/maize/data/data_conversion

$ perl ./convert_data.perl 15r DUMPDAY FLAG
#+END_SRC

FLAG = {test,q,go}

for each day on which data were dumped.  These will be the subdirectories
under *eta.

#+BEGIN_SRC 
$ ls ../palm/raw_data_from_palms/15r/*eta
../palm/raw_data_from_palms/15r/eta:
1.9     12.5    13.8    16.8    17.8    19.8    21.8    24.8    26.8    3.9     31.8
11.6    12.8    15.8    17.5    18.8    20.8    23.8    25.8    27.8    30.8    9.8

../palm/raw_data_from_palms/15r/zeta:
11.6    12.8    13.8    16.8    19.5    20.8    23.6    25.8    27.8    7.8
11.8    13.7    15.8    17.8    20.5    21.8    23.8    26.8    30.3    8.8

# or better,

ls ../palm/raw_data_from_palms/15r/*eta | sort | uniq

1.9 
11.6
11.8
12.5
12.8
13.7
13.8
15.8
16.8
17.5
17.8
18.8
19.5
19.8
20.5
20.8
21.8
23.6
23.8
24.8
25.8
26.8
27.8
3.9 
30.3
30.8
31.8
7.8 
8.8 
9.8 


#+END_SRC


Paste the column into emacs, add a leading space to dates that are too
short, and sort on the months to produce a nice listing in chronological
order:

30.3
12.5
17.5
19.5
20.5
11.6
23.6
13.7
11.8
12.8
13.8
15.8
16.8 next
17.8
18.8
19.8
20.8
21.8
23.8
24.8
25.8

26.8
27.8
30.8
31.8




 1.9 
 3.9 

Go in order of dumpdays.  To save time, check to be sure files from that
directory haven't already been added (they will be prefixed with "done.".).


#+BEGIN_SRC 
bash-3.2$ pushd ../palm/raw_data_from_palms/15r/
/athe/c/maize/data/palm/raw_data_from_palms/15r /athe/c/maize/data/data_conversion
bash-3.2$ ls */30.3 */*.5
eta/12.5:
done.inventory.csv		done.tags_to_replace.csv	tags_to_replace.csv

eta/17.5:
done.inventory.csv		tags_to_replace.csv
done.packed_packet.csv		uncorrected.packed_packet.csv

zeta/19.5:
done.packed_packet.csv		uncorrected.packed_packet.csv

zeta/20.5:
done.packed_packet.csv		uncorrected.packed_packet.csv

zeta/30.3:
done.packed_packet.csv
bash-3.2$ ls */*.6
eta/11.6:
done.planted.csv

zeta/11.6:
done.planted.csv

zeta/23.6:
done.planted.csv
bash-3.2$ ls */*.7
done.row_status.csv
bash-3.2$ ls */*.8
eta/12.8:
12.8_data_collection.zip	cross.csv			cross_prep.csv

eta/13.8:
13.8_data_collectn.csv		13.8_data_collectn.numbers	cross.csv

eta/15.8:
cross_prep.csv

eta/16.8:
16.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/17.8:
cross.csv

eta/18.8:
18.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/19.8:
19.8_data_collectn.zip	cross_prep.csv

eta/20.8:
20.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/21.8:
21.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/23.8:
23.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/24.8:
24.8_data_collectn.zip	cross.csv		cross_prep.csv		tissue_collectn.csv	tissue_todo.csv

eta/25.8:
25.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/26.8:
26.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/27.8:
27.8_data_collectn.zip	cross.csv		cross_prep.csv		plant_anatomy.csv

eta/30.8:
30.8_data_collectn.zip	cross.csv		cross_prep.csv		plant_anatomy.csv

eta/31.8:
31.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/9.8:
IMG_4779.JPG

zeta/11.8:
image.csv		tissue_collectn.csv

zeta/12.8:
mutanta.csv	plant_fate.csv

zeta/13.8:
image.csv

zeta/15.8:
image.csv		plant_fate.csv		tissue_collectn.csv

zeta/16.8:
plant_fate.csv

zeta/17.8:
image.csv

zeta/20.8:
image.csv	mutanta.csv

zeta/21.8:
mutanta.csv

zeta/23.8:
image.csv	mutanta.csv

zeta/25.8:
tissue_collectn.csv

zeta/26.8:
leaf_alignmt.csv	mutanta.csv

zeta/27.8:
tissue_collectn.csv

zeta/7.8:
plant_fate.csv

zeta/8.8:
image.csv		plant_fate.csv		tissue_collectn.csv
bash-3.2$ 

#+END_SRC

So we start in August.

#+BEGIN_SRC 
$ perl ./convert_data.perl 15r 11.8

f: ../palm/raw_data_from_palms/15r/zeta/11.8/image.csv
h: plantID,image no,abs_leaf_num,e0,section,camera,conditions,observer,datetime,image
m: image


f: ../palm/raw_data_from_palms/15r/zeta/11.8/tissue_collectn.csv
h: plantID,sample num,observer,datetime,tissue_collectn
m: tissue_collectn

no directory ../palm/raw_data_from_palms/15r/eta/11.8 found
no directory ../palm/raw_data_from_palms/15r/theta/11.8 found
no directory ../palm/raw_data_from_palms/15r/dalet/11.8 found

i: ../palm/raw_data_from_palms/15r/zeta/11.8/image.csv o: ../../demeter/data/image.pl s: convert_image_data.perl

i: ../palm/raw_data_from_palms/15r/zeta/11.8/tissue_collectn.csv o: ../../demeter/data/tissue_collectn.pl s: convert_tissue_collectn_data.perl


bash-3.2$ mv ../palm/raw_data_from_palms/15r/zeta/11.8/image.csv ../palm/raw_data_from_palms/15r/zeta/11.8/done.image.csv
bash-3.2$ mv ../palm/raw_data_from_palms/15r/zeta/11.8/tissue_collectn.csv ../palm/raw_data_from_palms/15r/zeta/11.8/done.tissue_collectn.csv
bash-3.2$ perl ./convert_data.perl 15r 12.8

f: ../palm/raw_data_from_palms/15r/zeta/12.8/mutanta.csv
h: plantID,wild_type,lesion,cross,photograph,sample,sample,stature,tassel,ear,other_phes,observer,datetime,mutanta
m: mutanta


f: ../palm/raw_data_from_palms/15r/zeta/12.8/plant_fate.csv
h: plantID,kicked down for light,sacrificed,dead,too slow to cross,observer,datetime,plant_fate
m: plant_fate


f: ../palm/raw_data_from_palms/15r/eta/12.8/cross.csv
h: ma plantID,pa plantID,ear1,ear2,repeat,bee,pilot,datetime,cross
m: cross


f: ../palm/raw_data_from_palms/15r/eta/12.8/cross_prep.csv
h: plantID,tassel_bagged,popped_tassel,cut_tassel,ear1_cut,ear2_cut,observer,datetime,cross_prep
m: cross_prep

no directory ../palm/raw_data_from_palms/15r/theta/12.8 found
no directory ../palm/raw_data_from_palms/15r/dalet/12.8 found

i: ../palm/raw_data_from_palms/15r/eta/12.8/cross.csv o: ../../demeter/data/cross.pl s: convert_cross_data.perl

i: ../palm/raw_data_from_palms/15r/eta/12.8/cross_prep.csv o: ../../demeter/data/cross_prep.pl s: convert_cross_prep_data.perl

i: ../palm/raw_data_from_palms/15r/zeta/12.8/mutanta.csv o: ../../demeter/data/mutant.pl s: convert_mutant_data.perl

i: ../palm/raw_data_from_palms/15r/zeta/12.8/plant_fate.csv o: ../../demeter/data/plant_fate.pl s: convert_plant_fate_data.perl
bash-3.2$ mv ../palm/raw_data_from_palms/15r/eta/12.8/cross.csv ../palm/raw_data_from_palms/15r/eta/12.8/done.cross.csv
bash-3.2$ mv ../palm/raw_data_from_palms/15r/eta/12.8/cross_prep.csv ../palm/raw_data_from_palms/15r/eta/12.8/done.cross_prep.csv
bash-3.2$ mv ../palm/raw_data_from_palms/15r/zeta/12.8/plant_fate.csv ../palm/raw_data_from_palms/15r/zeta/12.8/done.plant_fate.csv 
bash-3.2$ 


etc

#+END_SRC


OK, we didn't score bugs this year, so the mutant facts come out with a
space in the predicate.  So back to convert_mutant_data.perl, toggle out
the bug RE, and run again.  Notice that since I've moved the other files to
done.FILE, they don't get re-processed.

#+BEGIN_SRC 
bash-3.2$ perl ./convert_data.perl 15r 12.8

skipping ../palm/raw_data_from_palms/15r/zeta/12.8/done.plant_fate.csv, already processed


f: ../palm/raw_data_from_palms/15r/zeta/12.8/mutanta.csv
h: plantID,wild_type,lesion,cross,photograph,sample,sample,stature,tassel,ear,other_phes,observer,datetime,mutanta
m: mutanta


skipping ../palm/raw_data_from_palms/15r/eta/12.8/done.cross.csv, already processed


skipping ../palm/raw_data_from_palms/15r/eta/12.8/done.cross_prep.csv, already processed

no directory ../palm/raw_data_from_palms/15r/theta/12.8 found
no directory ../palm/raw_data_from_palms/15r/dalet/12.8 found

i: ../palm/raw_data_from_palms/15r/zeta/12.8/mutanta.csv o: ../../demeter/data/mutant.pl s: convert_mutant_data.perl


#+END_SRC

