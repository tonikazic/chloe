how to generate pedigrees, plant tags, field book, and harvest plan
revised <2014-06-02 Mon> :toni:
again revised <2015-09-25 Fri> :toni:

More revisions needed! <2018-07-21 Sat>


* TODO write code to reassign sleeves after compression!


* TODO write pedigree integrity checks

  One is to compute
    the pedigrees by crop and rowplant, rather than by unifying on the
    entire numerical genotype, and compare the two versions.  The other is
    to check for changes in gene and K number assignments along the
    pedigree. 


* DONE preliminaries


1. be sure that [[file:../../demeter/data/crop.pl][crop.pl]] includes all crops that have yielded
offspring.  Usually the most recent crop will be missing.  It must be
present, or none of its offspring will appear in the pedigrees.


2.  Be sure corn is filed in inventory order:
   + mutants first, by rowplant (includes crop improvement, selves, etc.);
   + inbreds next, by family and then rowplant;
   + fun corn last.


3.  *Be sure to physically discard all corn* marked "discarded" or
    "ambiguous" in [[file:../../demeter/data/harvest.pl][harvest.pl]]! 


4.  Ensure [[file:../../demeter/data/inventory.pl][inventory.pl]] is current, running [[file:../../data/data_conversion/update_inventory.perl][update_inventory.perl]] with the
    last crop if needed.  Corn is now sorted automatically into inventory
    order and sleeve numbers inserted from [[file:../../demeter/data/sleeve_bdry.pl][sleeve_bdry.pl]].


5.  If corn has been compressed, reassign sleeves.






* DONE index computation on machines
<<indexing>>

1.  Tar up the old version of the data.  Today's date is inserted into the
    archive name:

#+BEGIN_SRC sample tar command
$ pwd
../c/maize/demeter
$ tar cvf archival/db_data.31.7.2018.tar data/*.pl data/*.org
$ ls -lt archival/
total 88496
-rw-r--r--   1 toni  staff  45307904 Jul 31 13:54 db_data.31.7.2018.tar
drwxr-xr-x  11 toni  staff       374 Jul 22 08:05 obsolete_code
drwxr-xr-x  11 toni  staff       374 Jul 22 05:29 obsolete_data
drwxr-xr-x  17 toni  staff       578 May 18 18:57 16r_data_reconstructn
drwxr-xr-x  12 toni  staff       408 May 18 18:56 17r_data_reconstructn

#+END_SRC



2.  Recalculate indices using [[file:../../demeter/code/genetic_utilities][make_indices/5]].  Errors and crashes are
    likely to be from incomplete data, not bugs in the code.  The most
    likely culprits are missing [[file:../../demeter/data/packed_packet.pl][packed_packet/7]], [[file:../../demeter/data/planted.pl][planted/8]], [[file:../../demeter/data/genotype.pl][genotype/11]],
    and [[file:../../demeter/data/harvest.pl][harvest/7]] facts.  Rows that were planted twice are now commented
    out in [[file:../../demeter/data/planted.pl][planted/8]], so no editing of [[file:../../demeter/data/planting_index.pl][planting_index/4]] facts or computing
    indices in two steps are needed.


3.  Check compilation of the data and make a save state.  You shouldn't
    have any syntax errors.  To make the save state,

#+BEGIN_SRC 
$ pwd
../c/maize/demeter/code

$ swipl
.... messages ....

?- ['../data/load_data',set_demeter_directory],qsave_program('../data/saved_data').
.... messages ....
#+END_SRC



Then halt and restart the prolog process:

#+BEGIN_SRC 
$ ../data/saved_data
#+END_SRC




* DONE pedigree computation

1.  calculate current pedigress using [[file:../../demeter/code/pedigrees.pl][pedigrees:compute_pedigrees/1]]:

ascii output to ../c/maize/crops/CROP/planning/current_pedigrees 
pdf   output to ../c/maize/crops/CROP/planning/pdf_pedigrees     

The PDF versions are automatically generated and copied to the [[file:~/Dropbox/corn/CROP/pdf_pedigrees][dropbox
pdf_pedigrees directory]] for manual analysis and transfer among platforms.



If warnings appear, these should be copied and pasted into
[[file:../CROP/planning/warnings][warnings]] for manual checking.



2.  In the past, it was very helpful to compare this crop's pedigrees with
    the last crop's.  Of course, the last crop's pedigrees won't have its
    offspring in the pedigree, so these must be ablated.  Follow directions
    in [[file:../scripts/ablate_crops_offspring.perl][ablate_crops_offspring.perl]] to do so. With changes in file names,
    this probably won't work anymore.


3.  Run the pedigree integrity checks.  One is to compute
    the pedigrees by crop and rowplant, rather than by unifying on the
    entire numerical genotype, and compare the two versions.  The other is
    to check for changes in gene and K number assignments along the
    pedigree. 


4.  This may take a few iterations of fact-checking, index compilation,
    and pedigree building.  We may gain branches in our pedigrees, but we
    shouldn't lose any previous branches except for an extremely good
    reason.  The pedigree calculation is based on numerical genotypes, not
    symbolic ones, so misassignment of genes and K numbers, etc., shouldn't
    affect the results UNTIL we compute tags and the field book.  Then it
    will matter a lot.  At this stage, the worst that can happen is that a
    line is in the wrong place in the field.



* DONE crop planning

** planning the crop

1.  With the pedigrees analyzed, write the [[file:../CROP/planning/packing_plan.org][packing_plan.org]] file.  This can
    be done /de novo/; generated from the prior crop's packing_plan.org
    file using [[file:../scripts/merge_plan_data.perl][merge_plan_data.perl]] and edited; or copying an earlier
    packing_plan.org file and editing that.


However this is done, the key elements are:
   + the experimental and management goals for that crop;
   + the tables for computing numbers of lines, inbreds, and stakes;
   + the packing_plan/9 facts, one for each row and half-row, embedded in
     org code blocks, e.g.,

#+BEGIN_EXAMPLE

#+begin_src prolog :tangle yes
packing_plan(,1,['09R201:S0xxxxxx','09R201:S0xxxxxx'],1,[inbred],'','',20,20).
#+end_src

#+END_EXAMPLE


2.  Edit the [[file:../CROP/planning/packing_plan.org][packing_plan.org]] file to represent what we really want to
    do. Remove the old crop header and leave just table stubs.  Note that
    there should be NO Crop argument in the packing_plan/9 facts at this point.

   + Insert the packing_plan facts between prolog source code blocks as
     these can be automatically tangled into source code.

   + Hand-correct cl and ft fields for inbreds, and other lines as needed.

   + Skip one line between sets, multiple lines between mutants.

   + If there are spreadsheet data from Gerry, convert them from Gerry's
     spreadsheet into packing_plan/10 by hand.  BE CAREFUL!  Not every row
     has a line in his spreadsheet, but does have a card in his field book.

   + Different types of lines can be counted by hand, by grepping and wc,
     or by using [[file:../scripts/count_lines.perl][count_lines.perl]] to compute the summary tables and
     generate [[file:../CROP/planning/line_counts.org][line_counts.org]] in the CROP/planning subdirectory.  Copy
     those tables into [[file:../CROP/planning/packing_plan.org][packing_plan.org]], straighten lines, and compute each
     table twice.




Once the packing_plan.org file is complete, export it to
[[file:../CROP/planning/packing_plan.prolog][packing_plan.prolog]] using C-c C-v t (see the [[https://orgmode.org/manual/Extracting-source-code.html#Extracting-source-code][orgmode export man page]]).
This file will be used in the subsequent steps.





** to number rows:

1. The input to [[file:/athe/c/maize/crops/merge_plan_data.perl]] to number rows is:

packing_plan(,NumPackets,etAlternativeParents,Plntg,CrossInstructns,SetInstructions,
                   KNum,Cl,Ft).

nb: no Crop argument, this will be inserted on generating row sequence
numbers.



2. run  [[file:../c/maize/crops/merge_plan_data.perl][merge_plan_data.perl]] on [[file:../CROP/planning/packing_plan.prolog][packing_plan.prolog]] /in sequence mode/ to
insert row numbers and Crop argument.

call is perl ./merge_plan_data.perl sequence CURRENT_CROP


nb: Check to be sure all the packing_plan/9 facts have made it through!
When editing the packing_plan.org file, it's easy to forget a code block
statement or have a syntax error in a fact that prevents parsing.  A good
way to check is to 


#+BEGIN_SRC 
grep packing_plan packing_plan.org > pp
#+END_SRC

edit pp to remove extraneous lines; edit packing_plan.prolog to remove
blank lines; and then diff and wc the two files against each other.



* GNG revise packing and planting


** packet labels (and plan, if prolog)


Ideally, one uses the file generated by prolog.  But it may be necessary to
generate labels directly from sequenced.packing_plan.pl using perl.


*** new perl-based procedure for just the packet labels

1.  Use [[file:../scripts/make_seed_packet_file.perl][make_seed_packet_file.perl]] to generate the packet data for
    packing seed from the [[file:../CROP/planning/sequenced.packing_plan.pl][sequenced.packing_plan.pl]] file.  This latter
    file was generated by [[file:../scripts/merge_plan_data.perl][merge_plan_data.perl]] using operation sequence.
    The output is the [[file:../CROP/planning/seed_packet_labels][seed_packet_labels]] file, which is input to
    [[file:../../label_making/make_seed_packet_labels.perl][make_seed_packet_labels.perl]]. 


2.  The script assumes a single parental line is already correctly chosen
    for packing.  Changes to this plan can occur in the seed room due to
    incorrect inventory counts, poor kernel state, or apparent defective
    kernels.  For this reason, the actual packed_packet data are the final
    authority. 


3.  The script [[file:../scripts/make_seed_packet_file.perl][make_seed_packet_file.perl]] must be revised to include the
    current inventory sleeve for each packet.



4.  Until that is done, the packets must be re-ordered into inventory order
    manually before generating the actual labels.  The trial algorithm in
    crop_management.pl is incorrect, but new algorithm in
    [[file:../../data/data_conversion/update_inventory.perl][update_inventory.perl]] is correct (multidimensional hash of hashes!).


      + mutants, sorted by crop, and then by type, and then rowplant within type.

      + inbreds, sorted by type, and then by row (planting usually will do fine).

      + then new accessions, which are filed in box0.



5. Ensure [[file:../CROP/{management,tags}][{management,tags}]] and [[file:../../barcodes/CROP][barcodes/CROP]] subdirectories exist.


6. Run [[file:../../label_making/make_seed_packet_labels.perl][make_seed_packet_labels.perl]] to generate the stickers and print on
   the Avery 1 x 2 5/8 inch 30-up labels (Avery 5160).








*** GNG old prolog-based procedure to generate packets and plan


1. move [[file:../CROP/planning/sequenced.packing_plan.pl][sequenced.packing_plan.pl]] to [[file:../CROP/planning/packing_plan.pl][packing_plan.pl]].


2.  use pack_corn:pack_corn/1 to generate plan/6, packet labels, and row
sequence labels.   Include the inbreds so that every packet has the correct
row number.



   + input to pack_corn/1:

#+begin_src prolog :tangle no

packing_plan(RowSequenceNum,NumPackets,
                   SetAlternativeParents,Plntg,CrossInstructns,SetInstructions,
                   KNum,Crop,Cl,Ft)

#+end_src


   + make sure current_crop:current_crop/1 is up to date.

   + make sure current_inbred:current_inbred/5 is up to date:  copy the
     prior crop's facts, change the crop, and make sure parents are ok.

   + make sure inbreds listed in packing_plan.org are really the current
     inbreds!  check [[file:/athe/c/maize/demeter/data/genotype.pl][genotype.pl]] to be sure.


3. Predicate will fail if harvest facts absent!


4. Results are dumped into [[file:phasma:/home/toni/demeter/results/CROP_planning/][my phasma demeter directory]].  They must be tarred
up and scped to athe.

5. Hmmm, I don't think plan is generated here . . . double-check code.  I
might have to revise the predicate to dump the incremental plan to my home
directory on phasma, then copy into [[file:/athe/c/maize/demeter/data/plan.pl][plan.pl]].






** packing

1. Pack corn, generating packed_packet/7 facts from packed_packet.csv using
   [[file:../../data/data_conversion/convert_data.perl][convert_data.perl]].  Check carefully for any missing packing_plan facts
   as these will cause the packet to be missed.




2.  Pack the corn.  Students can pack inbreds relatively unsupervised ---
    one {person,team}/inbred/bench!  

   + :toni: and experienced students pack mutants, but they can have help
     fetching and scanning. 

   + after packing and conversion of data to Prolog, grep out packet facts
     into [[file:/athe/c/maize/CROP/management/all_packed_packets.org][an org file]], order the packets by number, and check that each
     number is 1 more than the previous one.  Run down missing numbers and
     insert facts manually into [[file:/athe/c/maize/demeter/data/packed_packet.pl][packed_packet.pl]], and check that packets
     are really present in the seed to be planted.


** planting

1. Lay out field using four tape measures to get the corners square enough.

2. If soybeans, cover those rows with black paper until after Chris has
   sprayed with herbicide, then plant.

3. Plant corn, recording and generating planted/8 facts. These must be
   confected for the winter nursery from work order spreadsheet, since they
   don't scan the packets or stakes!

4. Use hand jab planters for experimental corn until the Earthway is
   thoroughly tested. 

5. When using the Earthway, measure directly the depth of the furrow made
   by the drill (don't trust its gauge); push the Earthway, and especially
   its back wheel, /downwards into/ the soil to firm the soil over the
   seed.  When this is done, there is no need to firm the soil by foot
   pressure, as we do with the jab planter.  As with the jab planter, a
   deeper depth mitigates bird damage.  As of <2018-07-01 Sun>, the
   Earthway can be used for border and fun corn.

6. Wait to place the twinkle tape until after Chris has sprayed with
   herbicide.  Leave it up until the seedlings have several leaves.




* DONE post-planting data collection

Collect row_status facts for stand counts, confecting if necessary for
winter nursery.

   + It is extremely important to accurately collect these data!

   + Go through the field systematically, looking at every row, each time.
     When we've just looked at rows that were empty and skipped around, we
     had a lot of missing data!

   + Two people are better at this job, one to count and call out the
     result, and the other to record.  WALK DOWN THE ROW --- do not rely on
     standing at one end of the row and eyeballing!  Even baby plants hide
     behind each other.  Beats me how they do it, but they know you are
     looking at them and duck.



* DONE generation of new family numbers, genotypes, and plant tags


If lines that were not previously planted are planted in the current crop,
then their families and genotypes will not have been assigned.  So run
[[file:../../demeter/code/crop_management.pl][crop_management:generate_plant_tags_file/3]] to get the new family numbers
and tentative fgenotype/11 facts; manually revise the fgenotype/11 facts
into genotype/11 facts; make a new save state of the data; and re-compute
the tags.  The fgenotype/11 facts are appended to the end of [[file:../../demeter/data/genotype.pl][genotype.pl]]:
revisions occur in that file.


Several iterations may be needed to ensure all new lines have genotypes.
At the end, there should be no new family numbers assigned, though some
warnings may persist (but shouldn't).


Mutant family numbers are issued consecutively, beginning with the last
mutant line added.  No gaps in numbers due to retirement of the fact are
filled in,  no numbers are reused, and a line receives only one family
number, no matter how many rows of it are planted in the same crop.


[[file:../../demeter/code/crop_management.pl][crop_management:generate_plant_tags_file/3]] assumes a list of rows in order
of priority for some action requiring tags ([[file:../../demeter/code/priority_rows.pl][priority_rows/2]]).  For us,
these actions are photography and pollinations.  This list is compiled by
walking around the field and assessing the plants.  The rows are grouped
first by priority category, and then ordered by row number for easier
tagging.  There can be gaps in the row numbers, but all rows that should
eventually be tagged should be represented, since the tags file is printed
and sawn only once.





[[file:../../demeter/code/crop_management.pl][crop_management:generate_plant_tags_file/3]] generates [[file:../CROP/management/plant_list.csv][the plant_list.csv]] in
the appropriate CROP/management directory.  This file is then processed with
[[file:../scripts/make_plant_tags.perl][make_plant_tags.perl]] to produce the tags file for printing.  I have
separated the two steps, rather than calling the perl script from the
prolog, so it is easier to fix problems.  The output file
[[file:../CROP/tags/prioritized_tags.ps][prioritized_tags.ps]] file appears in the CROP/tags directory.  This file
should be opened in Preview or other postscript reader, checked for obvious
errors, and then /printed in landscape mode to US legal size (8.5 x 14") as
a pdf/. 


The pdf file is then taken to Fedex for printing on 100 lb 11 x 17" matte
cardstock.  The sheets are cut to legal size and the tear-off tags
perforated after printing.  The resulting block of tags is then taken to
the machinist for drilling and sawing.  It usually takes Fedex several days
to print, cut, and perforate the tags: allow a week, as they may not have
sufficient cardstock and have to order more (a slow and error-prone
process).  Perforation is the slow step, since each sheet must be
individually done.


Yes, it's possible to re-use the sheets if they were printed incorrectly
<2015-08-05 Wed>. 


When looking at the block with the printing down, the right-most column of
tags is numbers 1 (upper) and 2 (lower); the next is 3 and 4, etc.  Usually
the block must be divided in half to fit in the fixture for sawing, with a
pink sheet inserted at the division.  Holes for the pins are drilled first
at the top edge.  Then the blocks are sawn and racked on the pins,
rubber-banded, slipped into numbered tassel bags, rubber-banded again, and
put in the tag box.  Thus, the machinist receives:
   + the tag block;
   + 32 or more thick rubber bands;
   + 16 pins;
   + 16 numbered blocks to stop the pins;
   + 16 numbered tassel bags;
   + all in the tag box.


Allow at least a week for the machinist to drill and saw the tags.



* GNG making the plan/6 facts



*** TODO merging previous plans

. Run [[file:../scripts/merge_plan_data.perl][merge_plan_data.perl]] in operation merge to
fuse the prior year's packing_plan.pl and last year's final plan
information, stripping out row number and crop identifier.

call is perl ./merge_plan_data.perl merge  CURRENT_CROP PRIOR_CROP


. 




*** GNG /de novo/ plan/6 generation

1.  Recompute the indices after planting is finished (see [[indexing]] above).
    [[file:../../demeter/data/planting_index.pl][planting_index/4]] gives what was actually planted in each row,
    simplifying flagging any revisions needed to the anticipated plans.

    It can happen that family numbers are changed, or different seed packed
    than what was planned, or there are scanning errors during packing,
    between the time the packing_plan.org file is written and the corn is
    planted.  By showing what was actually planted in the most
    contemporaneous packet packed, [[file:../../demeter/data/planting_index.pl][planting_index/4]] helps pin down these
    discrepancies for resolution.  The [[file:../../demeter/data/genotype.pl][genotype/11]] facts rule: usually the
    packed_packet facts will be ok, but the two packing_plan files may need
    editing to get everything to jibe.



2.  Export [[file:../c/maize/crops/CROP/planning/packing_plan.org][packing_plan.org]] to prolog and run 





* DONE field book production

1.  Recompute the indices after planting is finished (see [[indexing]] above).
    [[file:../../demeter/data/planting_index.pl][planting_index/4]] gives what was actually planted in each row,
    simplifying flagging any revisions needed to the anticipated plans.

    It can happen that family numbers are changed, or different seed packed
    than what was planned, or there are scanning errors during packing,
    between the time the packing_plan.org file is written and the corn is
    planted.  By showing what was actually planted in the most
    contemporaneous packet packed, [[file:../../demeter/data/planting_index.pl][planting_index/4]] helps pin down these
    discrepancies for resolution.  The [[file:../../demeter/data/genotype.pl][genotype/11]] facts rule: usually the
    packed_packet facts will be ok, but the two packing_plan files may need
    editing to get everything to jibe.




2.  Run [[file:../../demeter/code/analyze_crop.pl][make_field_book/2]] on all remedied data, reindexed and stored in a
    new save state.  This makes a nice file, now suitable for ipad and
    iphone6.  This requires either packing_plan/10 facts or the plan/6
    facts.  

    The plan/6 facts may have incorrect markers or K numbers compared to
    the packing_plan file.  This happens through mis-identification of the
    marker in the genotype/11 facts.  Correct, make a new save state, and
    check again.

    [[file:../../demeter/code/analyze_crop.pl][make_field_book/2]] should be run each time there are new observations or
    plans to be incorporated into the plan/6 facts.

    Someday add automatically generated cut-down jpegs of images . . .




3.  If needed, independently check prolog field book by running
    crops/check_row_assignments.perl.  It gives the planting number, which
    is useful. (obsolete?)






* emergency plant tag and field book production


#+begin_rmk


<2014-06-19 Thu> :toni:

Trito needs to be shut down as the air conditioner is leaking, so we are
going to confect data for the second and third plantings, and the
row_status facts, then compute.  I've already fixed the family number
re-use problem.


#+end_rmk


** to confect planted/8 and row_status/7

. grepped second and third planting from sequenced.packing_plan.pl, which
has row numbers and ma and pa

. wrote clean_data:confect_planting_n_stand_count_data/4, which confected
dummy row_status facts for all planted and unplanted corn, and planted/8
facts for unplanted corn in the second and third plantings.


. sorted data in output file and appended, with appropriate comments, to
planted.pl and row_status.pl


. recomputed indices, plant tags, and field book per usual.  BUT we
discovered the directions needed a little work!



* harvest plan

. First clean any uncleaned data files.  Common errors are:
   + incomplete plant IDs (usually because tags wouldn't scan).  Keep track
     of these in [[file:/athe/c/maize/crops/CROP/management/tags_needed]] to
     simplify the task of filling in the first part of the string and
     generation of extra tags.
   + incorrectly formatted dates:  should be MM/DD/YYYY HH:MM:SS
   + missing data, such as image numbers or tissue tags

. Then remove the squiggle files.

#+BEGIN_SRC safe file deletion
 ls *eta/*/*~
eta/1.9/cross.csv~              eta/27.8/cross.csv~             zeta/15.8/tissue_collectn.csv~
eta/13.8/cross.csv~             eta/27.8/cross_prep.csv~        zeta/16.8/plant_fate.csv~
eta/15.8/cross_prep.csv~        eta/27.8/plant_anatomy.csv~     zeta/17.8/image.csv~
eta/16.8/cross_prep.csv~        eta/27.8/plant_height.csv~      zeta/20.8/image.csv~
eta/18.8/cross.csv~             eta/3.9/cross.csv~              zeta/20.8/mutanta.csv~
eta/18.8/cross_prep.csv~        eta/30.8/cross.csv~             zeta/21.8/mutanta.csv~
eta/20.8/cross_prep.csv~        eta/30.8/cross_prep.csv~        zeta/23.8/image.csv~
eta/21.8/cross.csv~             eta/30.8/plant_anatomy.csv~     zeta/23.8/mutanta.csv~
eta/21.8/cross_prep.csv~        eta/30.8/plant_height.csv~      zeta/25.8/tissue_colectn.csv~
eta/23.8/cross.csv~             eta/31.8/cross.csv~             zeta/26.8/leaf_alignmt.csv~
eta/23.8/cross_prep.csv~        eta/31.8/cross_prep.csv~        zeta/26.8/mutanta.csv~
eta/24.8/cross.csv~             zeta/11.8/image.csv~            zeta/27.8/tissue_collectn.csv~
eta/24.8/cross_prep.csv~        zeta/11.8/tissue_collectn.csv~  zeta/7.8/plant_fate.csv~
eta/24.8/tissue_collectn.csv~   zeta/12.8/mutanta.csv~          zeta/8.8/image.csv~
eta/25.8/cross.csv~             zeta/12.8/plant_fate.csv~       zeta/8.8/plant_fate.csv~
eta/25.8/cross_prep.csv~        zeta/13.8/image.csv~            zeta/8.8/tissue_collectn.csv~
eta/26.8/cross.csv~             zeta/15.8/image.csv~
eta/26.8/cross_prep.csv~        zeta/15.8/plant_fate.csv~

bash-3.2$ ^ls^rm
rm *eta/*/*~

#+END_SRC


.  Now read the data into prolog.

#+BEGIN_SRC 
$ cd ../../data_conversion/
$ pwd
/athe/c/maize/data/data_conversion

$ perl ./convert_data.perl 15r DUMPDAY
#+END_SRC

for each day on which data were dumped.  These will be the subdirectories
under *eta.

#+BEGIN_SRC 
$ ls ../palm/raw_data_from_palms/15r/*eta
../palm/raw_data_from_palms/15r/eta:
1.9     12.5    13.8    16.8    17.8    19.8    21.8    24.8    26.8    3.9     31.8
11.6    12.8    15.8    17.5    18.8    20.8    23.8    25.8    27.8    30.8    9.8

../palm/raw_data_from_palms/15r/zeta:
11.6    12.8    13.8    16.8    19.5    20.8    23.6    25.8    27.8    7.8
11.8    13.7    15.8    17.8    20.5    21.8    23.8    26.8    30.3    8.8

# or better,

ls ../palm/raw_data_from_palms/15r/*eta | sort | uniq

1.9 
11.6
11.8
12.5
12.8
13.7
13.8
15.8
16.8
17.5
17.8
18.8
19.5
19.8
20.5
20.8
21.8
23.6
23.8
24.8
25.8
26.8
27.8
3.9 
30.3
30.8
31.8
7.8 
8.8 
9.8 


#+END_SRC


Paste the column into emacs, add a leading space to dates that are too
short, and sort on the months to produce a nice listing in chronological
order:

30.3
12.5
17.5
19.5
20.5
11.6
23.6
13.7
11.8
12.8
13.8
15.8
16.8 next
17.8
18.8
19.8
20.8
21.8
23.8
24.8
25.8

26.8
27.8
30.8
31.8




 1.9 
 3.9 

Go in order of dumpdays.  To save time, check to be sure files from that
directory haven't already been added (they will be prefixed with "done.".).


#+BEGIN_SRC 
bash-3.2$ pushd ../palm/raw_data_from_palms/15r/
/athe/c/maize/data/palm/raw_data_from_palms/15r /athe/c/maize/data/data_conversion
bash-3.2$ ls */30.3 */*.5
eta/12.5:
done.inventory.csv		done.tags_to_replace.csv	tags_to_replace.csv

eta/17.5:
done.inventory.csv		tags_to_replace.csv
done.packed_packet.csv		uncorrected.packed_packet.csv

zeta/19.5:
done.packed_packet.csv		uncorrected.packed_packet.csv

zeta/20.5:
done.packed_packet.csv		uncorrected.packed_packet.csv

zeta/30.3:
done.packed_packet.csv
bash-3.2$ ls */*.6
eta/11.6:
done.planted.csv

zeta/11.6:
done.planted.csv

zeta/23.6:
done.planted.csv
bash-3.2$ ls */*.7
done.row_status.csv
bash-3.2$ ls */*.8
eta/12.8:
12.8_data_collection.zip	cross.csv			cross_prep.csv

eta/13.8:
13.8_data_collectn.csv		13.8_data_collectn.numbers	cross.csv

eta/15.8:
cross_prep.csv

eta/16.8:
16.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/17.8:
cross.csv

eta/18.8:
18.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/19.8:
19.8_data_collectn.zip	cross_prep.csv

eta/20.8:
20.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/21.8:
21.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/23.8:
23.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/24.8:
24.8_data_collectn.zip	cross.csv		cross_prep.csv		tissue_collectn.csv	tissue_todo.csv

eta/25.8:
25.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/26.8:
26.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/27.8:
27.8_data_collectn.zip	cross.csv		cross_prep.csv		plant_anatomy.csv

eta/30.8:
30.8_data_collectn.zip	cross.csv		cross_prep.csv		plant_anatomy.csv

eta/31.8:
31.8_data_collectn.zip	cross.csv		cross_prep.csv

eta/9.8:
IMG_4779.JPG

zeta/11.8:
image.csv		tissue_collectn.csv

zeta/12.8:
mutanta.csv	plant_fate.csv

zeta/13.8:
image.csv

zeta/15.8:
image.csv		plant_fate.csv		tissue_collectn.csv

zeta/16.8:
plant_fate.csv

zeta/17.8:
image.csv

zeta/20.8:
image.csv	mutanta.csv

zeta/21.8:
mutanta.csv

zeta/23.8:
image.csv	mutanta.csv

zeta/25.8:
tissue_collectn.csv

zeta/26.8:
leaf_alignmt.csv	mutanta.csv

zeta/27.8:
tissue_collectn.csv

zeta/7.8:
plant_fate.csv

zeta/8.8:
image.csv		plant_fate.csv		tissue_collectn.csv
bash-3.2$ 

#+END_SRC

So we start in August.

#+BEGIN_SRC 
$ perl ./convert_data.perl 15r 11.8

f: ../palm/raw_data_from_palms/15r/zeta/11.8/image.csv
h: plantID,image no,abs_leaf_num,e0,section,camera,conditions,observer,datetime,image
m: image


f: ../palm/raw_data_from_palms/15r/zeta/11.8/tissue_collectn.csv
h: plantID,sample num,observer,datetime,tissue_collectn
m: tissue_collectn

no directory ../palm/raw_data_from_palms/15r/eta/11.8 found
no directory ../palm/raw_data_from_palms/15r/theta/11.8 found
no directory ../palm/raw_data_from_palms/15r/dalet/11.8 found

i: ../palm/raw_data_from_palms/15r/zeta/11.8/image.csv o: ../../demeter/data/image.pl s: convert_image_data.perl

i: ../palm/raw_data_from_palms/15r/zeta/11.8/tissue_collectn.csv o: ../../demeter/data/tissue_collectn.pl s: convert_tissue_collectn_data.perl


bash-3.2$ mv ../palm/raw_data_from_palms/15r/zeta/11.8/image.csv ../palm/raw_data_from_palms/15r/zeta/11.8/done.image.csv
bash-3.2$ mv ../palm/raw_data_from_palms/15r/zeta/11.8/tissue_collectn.csv ../palm/raw_data_from_palms/15r/zeta/11.8/done.tissue_collectn.csv
bash-3.2$ perl ./convert_data.perl 15r 12.8

f: ../palm/raw_data_from_palms/15r/zeta/12.8/mutanta.csv
h: plantID,wild_type,lesion,cross,photograph,sample,sample,stature,tassel,ear,other_phes,observer,datetime,mutanta
m: mutanta


f: ../palm/raw_data_from_palms/15r/zeta/12.8/plant_fate.csv
h: plantID,kicked down for light,sacrificed,dead,too slow to cross,observer,datetime,plant_fate
m: plant_fate


f: ../palm/raw_data_from_palms/15r/eta/12.8/cross.csv
h: ma plantID,pa plantID,ear1,ear2,repeat,bee,pilot,datetime,cross
m: cross


f: ../palm/raw_data_from_palms/15r/eta/12.8/cross_prep.csv
h: plantID,tassel_bagged,popped_tassel,cut_tassel,ear1_cut,ear2_cut,observer,datetime,cross_prep
m: cross_prep

no directory ../palm/raw_data_from_palms/15r/theta/12.8 found
no directory ../palm/raw_data_from_palms/15r/dalet/12.8 found

i: ../palm/raw_data_from_palms/15r/eta/12.8/cross.csv o: ../../demeter/data/cross.pl s: convert_cross_data.perl

i: ../palm/raw_data_from_palms/15r/eta/12.8/cross_prep.csv o: ../../demeter/data/cross_prep.pl s: convert_cross_prep_data.perl

i: ../palm/raw_data_from_palms/15r/zeta/12.8/mutanta.csv o: ../../demeter/data/mutant.pl s: convert_mutant_data.perl

i: ../palm/raw_data_from_palms/15r/zeta/12.8/plant_fate.csv o: ../../demeter/data/plant_fate.pl s: convert_plant_fate_data.perl
bash-3.2$ mv ../palm/raw_data_from_palms/15r/eta/12.8/cross.csv ../palm/raw_data_from_palms/15r/eta/12.8/done.cross.csv
bash-3.2$ mv ../palm/raw_data_from_palms/15r/eta/12.8/cross_prep.csv ../palm/raw_data_from_palms/15r/eta/12.8/done.cross_prep.csv
bash-3.2$ mv ../palm/raw_data_from_palms/15r/zeta/12.8/plant_fate.csv ../palm/raw_data_from_palms/15r/zeta/12.8/done.plant_fate.csv 
bash-3.2$ 


etc

#+END_SRC


OK, we didn't score bugs this year, so the mutant facts come out with a
space in the predicate.  So back to convert_mutant_data.perl, toggle out
the bug RE, and run again.  Notice that since I've moved the other files to
done.FILE, they don't get re-processed.

#+BEGIN_SRC 
bash-3.2$ perl ./convert_data.perl 15r 12.8

skipping ../palm/raw_data_from_palms/15r/zeta/12.8/done.plant_fate.csv, already processed


f: ../palm/raw_data_from_palms/15r/zeta/12.8/mutanta.csv
h: plantID,wild_type,lesion,cross,photograph,sample,sample,stature,tassel,ear,other_phes,observer,datetime,mutanta
m: mutanta


skipping ../palm/raw_data_from_palms/15r/eta/12.8/done.cross.csv, already processed


skipping ../palm/raw_data_from_palms/15r/eta/12.8/done.cross_prep.csv, already processed

no directory ../palm/raw_data_from_palms/15r/theta/12.8 found
no directory ../palm/raw_data_from_palms/15r/dalet/12.8 found

i: ../palm/raw_data_from_palms/15r/zeta/12.8/mutanta.csv o: ../../demeter/data/mutant.pl s: convert_mutant_data.perl


#+END_SRC
